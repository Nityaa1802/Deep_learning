# -*- coding: utf-8 -*-
"""convolutional_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xz48O4lOtG0FXY78sZ6kMEH6k3nWK9Ah

# Convolutional Neural Network

> *ann cannot process the images as it takes the input in the vector form so if we have to process the images we can process then with the help of cnn as in cnn the convolution layes convert the image into a vector only so that it can be processed*

> *tensorflow is the library of deep learning introduces by google we are importing the image mode of this library*

### Importing the libraries
"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator

tf.__version__

"""## Part 1 - Data Preprocessing

### Preprocessing the Training set

>*we will transform the images in training set only because by transforming we dec the feature and this will not overtrain our model this is to avoid over fitting by transformation means doing zoom and adding horizornta flips etc*
> *we will size the training images by 64x64 and and we have mention binaary because we hae to categorize in dog or cat if there are more categorin we would have written category*
"""

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)
training_set = train_datagen.flow_from_directory('dataset/training_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

"""### Preprocessing the Test set

> *we will not transform the test set as no to distrb the originality of the image*
"""

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory('dataset/test_set',
                                            target_size = (64, 64),
                                            batch_size = 32,
                                            class_mode = 'binary')

"""## Part 2 - Building the CNN

### Initialising the CNN
"""

cnn = tf.keras.models.Sequential()

"""### Step 1 - Convolution

>*adding a convolution layer we have add 32 filters of size 3x3 these are the default values input shape will be in 3 dimentions because it s a colured image and it is in the RGB form so 64 id the target size and 3 is the filtr size if is bimary image we would hav written only 64x64*
"""

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))

"""### Step 2 - Pooling

>*adding a pooling layer in which the frame we have to do pooling is of 2x2 size and the pixels we hae to shift our frame in 2 pixels max pooling is the most used pooling pooling is for feature reduction and highighting the main feature from the image after pooling if we do any rotation or someting it will not affect the features*
"""

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Adding a second convolutional layer"""

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Step 3 - Flattening

>*converting the pixels into vectors*
"""

cnn.add(tf.keras.layers.Flatten())

"""### Step 4 - Full Connection"""

cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""### Step 5 - Output Layer"""

cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

"""## Part 3 - Training the CNN

### Compiling the CNN
"""

cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

"""### Training the CNN on the Training set and evaluating it on the Test set

>*we will train the model on training set and validate it on the test set*
"""

cnn.fit(x = training_set, validation_data = test_set, epochs = 25)

"""## Part 4 - Making a single prediction

>*as predict method takes 2D array as imput so we will convert the image in 2D array and make it size same as training data set ad we have train our model in batches so we have to give the test image in batch only so we have made a array of the image array by **np.expand_dims(test_image, axis = 0)** and then predit it*
"""

import numpy as np
from keras.preprocessing import image
test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = cnn.predict(test_image)
training_set.class_indices
if result[0][0] == 1:
  prediction = 'dog'
else:
  prediction = 'cat'

print(prediction)